type = "mbart"

[task]
change_ratio = 0.3
denoise_langs = []
poisson_lambda = 3.0
source_langs = ["br"]
target_langs = ["fr"]

[tuning]
batch_size = 8
betas = [0.9, 0.98]
epsilon = 1e-8
learning_rate = 1e-4
# Uncomment these for a more complex training setup
lr_decay_steps = 1000000
warmup_steps = 1000
weight_decay = 1e-5
