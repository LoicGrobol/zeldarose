type = "ntp"

# [task]
# Not task config for NTP

[tuning]
# The default MLM fine-tuning config
batch_size = 64
betas = [0.9, 0.98]
epsilon = 1e-8
learning_rate = 1e-4
lr_decay_steps = 1048567
warmup_steps = 1024
weight_decay = 1e-5
