type = "mbart"

[task]
change_ratio = 0.3
denoise_langs = ["fr"]
poisson_lambda = 3.0
source_langs = ["br", "fr"]
target_langs = ["br", "fr"]

[tuning]
batch_size = 4
betas = [0.9, 0.98]
epsilon = 1e-8
learning_rate = 1e-4
# Uncomment these for a more complex training setup
# lr_decay_steps = 1000000
# warmup_steps = 1000
#Â weight_decay = 1e-5